{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lstm_seq2seq_Spellcheck_Sentence",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/piyush0511/SpellChecker-AutoCorrect/blob/main/SpellCheck%20-%20seq2seq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0hVhAsFY0fPE"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4C-rZbxU0fPG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4329a0cc-fef0-4a04-b2e1-e5844feb60f9"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))\n",
        "import numpy as np\n",
        "from tensorflow import keras\n",
        "import random\n",
        "import string\n",
        "import pandas as pd\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import pickle"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QDlCOtCa0fPJ"
      },
      "source": [
        "## Download the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qCNYZFoX0fPL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b526d0c-b3a7-4e58-de10-bc75a7d40e1d"
      },
      "source": [
        "!!curl -O http://www.manythings.org/anki/fra-eng.zip\n",
        "!!unzip fra-eng.zip\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Archive:  fra-eng.zip',\n",
              " '  inflating: _about.txt              ',\n",
              " '  inflating: fra.txt                 ']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecuyvq-l0fPM"
      },
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwwS5dJF0fPO"
      },
      "source": [
        "batch_size = 64  # Batch size for training.\n",
        "epochs = 100  # Number of epochs to train for.\n",
        "latent_dim = 128  # Latent dimensionality of the encoding space.\n",
        "num_samples = 120000   # Number of samples to train on.\n",
        "# Path to the data txt file on disk.\n",
        "data_path = \"fra.txt\"\n",
        "output_dim = 64\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fGq8DaBm0fPQ"
      },
      "source": [
        "## Prepare the data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QynAASs0fPR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ad936d1-332b-403d-a3b2-7ecdc050011c"
      },
      "source": [
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "input_ =[]\n",
        "tar_ =[]\n",
        "input_characters = set()\n",
        "target_characters = set()\n",
        "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "  for _ in range(5):\n",
        "      input_text, target_text, _ = line.split(\"\\t\")\n",
        "      # We use \"tab\" as the \"start sequence\" character\n",
        "      # for the targets, and \"\\n\" as \"end sequence\" character.\n",
        "      #input_.append(input_text)\n",
        "      input_text = input_text.lower()\n",
        "      input_text = re.sub(r'[^a-zA-Z ]+', '', input_text)\n",
        "      target_text = \"\\t\" + input_text + \"\\n\"\n",
        "      for i in range(np.random.choice(np.arange(0, 2), p=[0.1, 0.9])):\n",
        "\n",
        "          input_text = input_text.replace(random.choice(list(input_text)),random.choice(string.ascii_letters))\n",
        "\n",
        "      input_texts.append(input_text.lower())\n",
        "      target_texts.append(target_text)\n",
        "      for char in input_text.lower():\n",
        "          if char not in input_characters:\n",
        "              input_characters.add(char)\n",
        "      for char in target_text:\n",
        "          if char not in target_characters:\n",
        "              target_characters.add(char)\n",
        "\n",
        "#d = {\"input_\" :input_,\"inps\": input_texts,\"targs\":target_texts }\n",
        "#df = pd.DataFrame(d)\n",
        "input_characters = sorted(list(input_characters))\n",
        "target_characters = sorted(list(target_characters))\n",
        "num_encoder_tokens = len(input_characters)\n",
        "num_decoder_tokens = len(target_characters)\n",
        "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
        "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
        "\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)\n",
        "\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])\n",
        "\n",
        "encoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_input_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "decoder_target_data = np.zeros(\n",
        "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens), dtype=\"float32\"\n",
        ")\n",
        "\n",
        "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
        "    for t, char in enumerate(input_text):\n",
        "        encoder_input_data[i, t, input_token_index[char]] = 1.0\n",
        "    encoder_input_data[i, t + 1 :, input_token_index[\" \"]] = 1.0\n",
        "    for t, char in enumerate(target_text):\n",
        "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
        "        decoder_input_data[i, t, target_token_index[char]] = 1.0\n",
        "        if t > 0:\n",
        "            # decoder_target_data will be ahead by one timestep\n",
        "            # and will not include the start character.\n",
        "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.0\n",
        "    decoder_input_data[i, t + 1 :, target_token_index[\" \"]] = 1.0\n",
        "    decoder_target_data[i, t:, target_token_index[\" \"]] = 1.0\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of samples: 600000\n",
            "Number of unique input tokens: 27\n",
            "Number of unique output tokens: 29\n",
            "Max sequence length for inputs: 31\n",
            "Max sequence length for outputs: 33\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR-45q9l0fPS"
      },
      "source": [
        "## Build the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eqcJXSpf0fPW"
      },
      "source": [
        "# Define an input sequence and process it.\n",
        "encoder_inputs = keras.Input(shape=(None, num_encoder_tokens))\n",
        "encoder = keras.layers.LSTM(latent_dim, return_state=True, dropout=0.2)\n",
        "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]\n",
        "\n",
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = keras.Input(shape=(None, num_decoder_tokens))\n",
        "\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True, dropout=0.2)\n",
        "decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation=\"softmax\")\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "011HNgPC0fPY"
      },
      "source": [
        "## Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l1QQlgUGePD0"
      },
      "source": [
        "model.compile(\n",
        "    optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1iR-Vda0fPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d967cb4-c9dd-4283-881b-2ea26ecb5595"
      },
      "source": [
        "\n",
        "model.fit(\n",
        "    [encoder_input_data, decoder_input_data],\n",
        "    decoder_target_data,\n",
        "    batch_size=batch_size,\n",
        "    epochs=1,\n",
        "    validation_split=0.2,\n",
        ")\n",
        "# Save model\n",
        "model.save(\"auto.h5\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7500/7500 [==============================] - 189s 25ms/step - loss: 0.3708 - accuracy: 0.8932 - val_loss: 0.7500 - val_accuracy: 0.7853\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zob6hqbcQ4mb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e72eae2-132a-45ce-cdb8-1bc563fb02e5"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_5\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            [(None, None, 27)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_10 (InputLayer)           [(None, None, 29)]   0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lstm_8 (LSTM)                   [(None, 128), (None, 79872       input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "lstm_9 (LSTM)                   [(None, None, 128),  80896       input_10[0][0]                   \n",
            "                                                                 lstm_8[0][1]                     \n",
            "                                                                 lstm_8[0][2]                     \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, None, 29)     3741        lstm_9[0][0]                     \n",
            "==================================================================================================\n",
            "Total params: 164,509\n",
            "Trainable params: 164,509\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhiikUDdSzdR"
      },
      "source": [
        "tf.keras.utils.plot_model(\n",
        "    model,\n",
        "    to_file=\"model.png\",\n",
        "    show_shapes=True,\n",
        "    show_dtype=False,\n",
        "    show_layer_names=True,\n",
        "    rankdir=\"TB\",\n",
        "    expand_nested=False,\n",
        "    dpi=96,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-2E4PYq60fPZ"
      },
      "source": [
        "## Run inference (sampling)\n",
        "\n",
        "1. encode input and retrieve initial decoder state\n",
        "2. run one step of decoder with this initial state\n",
        "and a \"start of sequence\" token as target.\n",
        "Output will be the next target token.\n",
        "3. Repeat with the current target token and current states\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuvNA11W0fPa"
      },
      "source": [
        "# Define sampling models\n",
        "# Restore the model and construct the encoder and decoder.\n",
        "model = keras.models.load_model(\"s2s\")\n",
        "\n",
        "encoder_inputs = model.input[0]  # input_1\n",
        "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output  # lstm_1\n",
        "encoder_states = [state_h_enc, state_c_enc]\n",
        "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "decoder_inputs = model.input[1]  # input_2\n",
        "decoder_state_input_h = keras.Input(shape=(latent_dim,), name=\"input_3\")\n",
        "decoder_state_input_c = keras.Input(shape=(latent_dim,), name=\"input_4\")\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "decoder_lstm = model.layers[3]\n",
        "decoder_outputs, state_h_dec, state_c_dec = decoder_lstm(\n",
        "    decoder_inputs, initial_state=decoder_states_inputs\n",
        ")\n",
        "decoder_states = [state_h_dec, state_c_dec]\n",
        "decoder_dense = model.layers[4]\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "decoder_model = keras.Model(\n",
        "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states\n",
        ")\n",
        "\n",
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())\n",
        "\n",
        "\n",
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq)\n",
        "\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
        "            stop_condition = True\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
        "        target_seq[0, 0, sampled_token_index] = 1.0\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "    return decoded_sentence\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-jpizE_20fPb"
      },
      "source": [
        "You can now generate decoded sentences as such:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dMTz-Quy0fPb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "882e945b-c7c9-434f-c53f-12861808fd27"
      },
      "source": [
        "out = pd.DataFrame(columns = [\"input\", \"decoded\", \"target\"])\n",
        "tt = 0\n",
        "for seq_index in tqdm(range(57300, 57400)):\n",
        "    # Take one sequence (part of the training set)\n",
        "    # for trying out decoding.\n",
        "    input_seq = encoder_input_data[seq_index : seq_index + 1]\n",
        "    decoded_sentence = decode_sequence(input_seq)\n",
        "    tar = re.sub(r'[^a-z ]+', '', target_texts[seq_index])\n",
        "    dec = re.sub(r'[^a-z ]+', '', decoded_sentence)\n",
        "    if tar == dec:\n",
        "      tt = tt+1\n",
        "    out.loc[len(out.index)] = [input_texts[seq_index], decoded_sentence, target_texts[seq_index]]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 100/100 [01:21<00:00,  1.22it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "xM4qGjIJ4mr-",
        "outputId": "1f59d8b8-ad45-4b48-8543-646faebd11e7"
      },
      "source": [
        "out.tail(20)\n",
        "#np.shape(input_seq)\n",
        "#tt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>decoded</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>uom misled you</td>\n",
              "      <td>tom missed you\\n</td>\n",
              "      <td>\\ttom misled you\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>tou uisled you</td>\n",
              "      <td>tom sigsed you\\n</td>\n",
              "      <td>\\ttom misled you\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>tomvmisledvyou</td>\n",
              "      <td>tom missed you\\n</td>\n",
              "      <td>\\ttom misled you\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>tgm misled ygu</td>\n",
              "      <td>tom missed you\\n</td>\n",
              "      <td>\\ttom misled you\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>tom misled you</td>\n",
              "      <td>tom missed you\\n</td>\n",
              "      <td>\\ttom misled you\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>tom misleo you</td>\n",
              "      <td>tom missed you\\n</td>\n",
              "      <td>\\ttom misled you\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>tomsmisledsyou</td>\n",
              "      <td>tom is ise you\\n</td>\n",
              "      <td>\\ttom misled you\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>tom misaed you</td>\n",
              "      <td>tom missed you\\n</td>\n",
              "      <td>\\ttom misled you\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>tomvmisledvyou</td>\n",
              "      <td>tom missed you\\n</td>\n",
              "      <td>\\ttom misled you\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>tom misled you</td>\n",
              "      <td>tom missed you\\n</td>\n",
              "      <td>\\ttom misled you\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>tom must ltavt</td>\n",
              "      <td>tom must thate\\n</td>\n",
              "      <td>\\ttom must leave\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>tom mvst leave</td>\n",
              "      <td>tom must leave\\n</td>\n",
              "      <td>\\ttom must leave\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>tom must lbavb</td>\n",
              "      <td>tom must leave\\n</td>\n",
              "      <td>\\ttom must leave\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>tomfmustfleave</td>\n",
              "      <td>tom must leave\\n</td>\n",
              "      <td>\\ttom must leave\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>tom muvt leave</td>\n",
              "      <td>tom must leave\\n</td>\n",
              "      <td>\\ttom must leave\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>too needed you</td>\n",
              "      <td>tom needed you\\n</td>\n",
              "      <td>\\ttom needed you\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>tomfneededfyou</td>\n",
              "      <td>tom needed you\\n</td>\n",
              "      <td>\\ttom needed you\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>tomzneededzyou</td>\n",
              "      <td>tom needed you\\n</td>\n",
              "      <td>\\ttom needed you\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>tlm needed ylu</td>\n",
              "      <td>tom nevers you\\n</td>\n",
              "      <td>\\ttom needed you\\n</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>tom needed you</td>\n",
              "      <td>tom needed you\\n</td>\n",
              "      <td>\\ttom needed you\\n</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             input           decoded              target\n",
              "80  uom misled you  tom missed you\\n  \\ttom misled you\\n\n",
              "81  tou uisled you  tom sigsed you\\n  \\ttom misled you\\n\n",
              "82  tomvmisledvyou  tom missed you\\n  \\ttom misled you\\n\n",
              "83  tgm misled ygu  tom missed you\\n  \\ttom misled you\\n\n",
              "84  tom misled you  tom missed you\\n  \\ttom misled you\\n\n",
              "85  tom misleo you  tom missed you\\n  \\ttom misled you\\n\n",
              "86  tomsmisledsyou  tom is ise you\\n  \\ttom misled you\\n\n",
              "87  tom misaed you  tom missed you\\n  \\ttom misled you\\n\n",
              "88  tomvmisledvyou  tom missed you\\n  \\ttom misled you\\n\n",
              "89  tom misled you  tom missed you\\n  \\ttom misled you\\n\n",
              "90  tom must ltavt  tom must thate\\n  \\ttom must leave\\n\n",
              "91  tom mvst leave  tom must leave\\n  \\ttom must leave\\n\n",
              "92  tom must lbavb  tom must leave\\n  \\ttom must leave\\n\n",
              "93  tomfmustfleave  tom must leave\\n  \\ttom must leave\\n\n",
              "94  tom muvt leave  tom must leave\\n  \\ttom must leave\\n\n",
              "95  too needed you  tom needed you\\n  \\ttom needed you\\n\n",
              "96  tomfneededfyou  tom needed you\\n  \\ttom needed you\\n\n",
              "97  tomzneededzyou  tom needed you\\n  \\ttom needed you\\n\n",
              "98  tlm needed ylu  tom nevers you\\n  \\ttom needed you\\n\n",
              "99  tom needed you  tom needed you\\n  \\ttom needed you\\n"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_tcjp4t5RR6"
      },
      "source": [
        "f = open('var.pkl','wb')\n",
        "jj = {\"input_token_index\":input_token_index, \"target_token_index\":target_token_index, \"num_decoder_tokens\": num_decoder_tokens, \"max_encoder_seq_length\":max_encoder_seq_length, \"num_encoder_tokens\": num_encoder_tokens}\n",
        "pickle.dump(jj, f)\n",
        "f.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXGtpjPX5NFh"
      },
      "source": [
        "f = open('var.pkl', 'rb')\n",
        "obj = pickle.load(f)\n",
        "f.close()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uffDllUq8Ct3",
        "outputId": "a62b4524-3cb7-4125-dfba-76f3f02bdda2"
      },
      "source": [
        "obj[\"tar\"]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\t': 0,\n",
              " '\\n': 1,\n",
              " ' ': 2,\n",
              " 'a': 3,\n",
              " 'b': 4,\n",
              " 'c': 5,\n",
              " 'd': 6,\n",
              " 'e': 7,\n",
              " 'f': 8,\n",
              " 'g': 9,\n",
              " 'h': 10,\n",
              " 'i': 11,\n",
              " 'j': 12,\n",
              " 'k': 13,\n",
              " 'l': 14,\n",
              " 'm': 15,\n",
              " 'n': 16,\n",
              " 'o': 17,\n",
              " 'p': 18,\n",
              " 'q': 19,\n",
              " 'r': 20,\n",
              " 's': 21,\n",
              " 't': 22,\n",
              " 'u': 23,\n",
              " 'v': 24,\n",
              " 'w': 25,\n",
              " 'x': 26,\n",
              " 'y': 27,\n",
              " 'z': 28}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4YX9_umD8jmR"
      },
      "source": [
        "pp = keras.models.load_model(\"auto.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ec4TGktFEJ4W"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}